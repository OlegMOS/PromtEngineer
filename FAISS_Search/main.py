import pandas as pd
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
import re
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
import nest_asyncio
import asyncio
import os
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

# –ê–∫—Ç–∏–≤–∞—Ü–∏—è nest_asyncio –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ Jupyter/Colab
nest_asyncio.apply()


class ResumeSearchEngine:
    def __init__(self, excel_file_path):
        self.df = pd.read_excel(excel_file_path)
        self.model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        self.index = None
        self.resume_texts = []

    def preprocess_data(self):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""
        print("–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

        # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        text_columns = ['positionName', 'experience', 'educationList', 'workExperienceList',
                        'hardSkills', 'softSkills', 'scheduleType', 'busyType']

        for col in text_columns:
            if col in self.df.columns:
                self.df[col] = self.df[col].fillna('')

        # –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–µ–∑—é–º–µ
        for idx, row in self.df.iterrows():
            resume_text = f"–î–æ–ª–∂–Ω–æ—Å—Ç—å: {row.get('positionName', '')}. "

            if row.get('experience', ''):
                resume_text += f"–û–ø—ã—Ç: {row['experience']} –ª–µ—Ç. "

            # –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
            if pd.notna(row.get('educationList')) and row['educationList']:
                edu_text = str(row['educationList']).replace('[', '').replace(']', '').replace('{', '').replace('}', '')
                resume_text += f"–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ: {edu_text}. "

            # –û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã
            if pd.notna(row.get('workExperienceList')) and row['workExperienceList']:
                exp_text = str(row['workExperienceList'])[:500]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                resume_text += f"–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã: {exp_text}. "

            # –ù–∞–≤—ã–∫–∏
            if pd.notna(row.get('hardSkills')) and row['hardSkills']:
                skills_text = str(row['hardSkills']).replace('[', '').replace(']', '').replace('{', '').replace('}', '')
                resume_text += f"–ù–∞–≤—ã–∫–∏: {skills_text}. "

            # –ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ
            if pd.notna(row.get('localityName')) and row['localityName']:
                location = str(row['localityName']).replace('-', ' ')
                resume_text += f"–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ: {location}. "

            self.resume_texts.append(resume_text)

        print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(self.resume_texts)} —Ä–µ–∑—é–º–µ")

    def create_faiss_index(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö FAISS"""
        print("–°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π...")

        # –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        embeddings = self.model.encode(self.resume_texts, show_progress_bar=True)

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤ –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞
        faiss.normalize_L2(embeddings)

        # –°–æ–∑–¥–∞–Ω–∏–µ FAISS –∏–Ω–¥–µ–∫—Å–∞
        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatIP(dimension)  # IndexFlatIP –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞
        self.index.add(embeddings.astype('float32'))

        print(f"–ò–Ω–¥–µ–∫—Å FAISS —Å–æ–∑–¥–∞–Ω —Å {self.index.ntotal} –≤–µ–∫—Ç–æ—Ä–∞–º–∏")

    def keyword_search(self, query, k=10):
        """–ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
        query_embedding = self.model.encode([query])
        faiss.normalize_L2(query_embedding)

        # –ü–æ–∏—Å–∫ –≤ FAISS
        scores, indices = self.index.search(query_embedding.astype('float32'), k)

        results = []
        for score, idx in zip(scores[0], indices[0]):
            if idx < len(self.df):
                results.append({
                    'index': idx,
                    'score': float(score),
                    'type': 'keyword'
                })

        return results

    def location_search(self, location_query, k=10):
        """–ü–æ–∏—Å–∫ –ø–æ –≥–µ–æ–ª–æ–∫–∞—Ü–∏–∏"""
        location_results = []

        for idx, row in self.df.iterrows():
            if pd.notna(row.get('localityName')):
                location = str(row['localityName']).lower().replace('-', ' ')
                query = location_query.lower()

                # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –ø–æ –≤—Ö–æ–∂–¥–µ–Ω–∏—é
                if query in location:
                    score = 1.0
                else:
                    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–¥—Å—Ç–≤–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö —Å–ª–æ–≤
                    location_words = set(location.split())
                    query_words = set(query.split())
                    common_words = location_words.intersection(query_words)

                    if common_words:
                        score = len(common_words) / len(query_words)
                    else:
                        score = 0.0

                if score > 0:
                    location_results.append({
                        'index': idx,
                        'score': score,
                        'type': 'location'
                    })

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∏ –≤–æ–∑–≤—Ä–∞—Ç —Ç–æ–ø-k —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        location_results.sort(key=lambda x: x['score'], reverse=True)
        return location_results[:k]

    def hybrid_search(self, keyword_query, location_query, k=5, keyword_weight=0.3, location_weight=0.7):
        """–ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ —Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        print(f"–ü–æ–∏—Å–∫: '{keyword_query}' –≤ –ª–æ–∫–∞—Ü–∏–∏ '{location_query}'")

        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–±–æ–∏—Ö –ø–æ–∏—Å–∫–æ–≤
        keyword_results = self.keyword_search(keyword_query, k=20)
        location_results = self.location_search(location_query, k=20)

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è score
        if keyword_results:
            max_keyword_score = max(r['score'] for r in keyword_results)
            for r in keyword_results:
                r['normalized_score'] = r['score'] / max_keyword_score if max_keyword_score > 0 else 0
        else:
            max_keyword_score = 1.0

        if location_results:
            max_location_score = max(r['score'] for r in location_results)
            for r in location_results:
                r['normalized_score'] = r['score'] / max_location_score if max_location_score > 0 else 0
        else:
            max_location_score = 1.0

        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        combined_results = {}

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ keyword –ø–æ–∏—Å–∫–∞
        for result in keyword_results:
            idx = result['index']
            combined_results[idx] = {
                'index': idx,
                'keyword_score': result['normalized_score'],
                'location_score': 0,
                'final_score': result['normalized_score'] * keyword_weight
            }

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ location –ø–æ–∏—Å–∫–∞
        for result in location_results:
            idx = result['index']
            if idx in combined_results:
                combined_results[idx]['location_score'] = result['normalized_score']
                combined_results[idx]['final_score'] = (
                        combined_results[idx]['keyword_score'] * keyword_weight +
                        result['normalized_score'] * location_weight
                )
            else:
                combined_results[idx] = {
                    'index': idx,
                    'keyword_score': 0,
                    'location_score': result['normalized_score'],
                    'final_score': result['normalized_score'] * location_weight
                }

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∏—Ç–æ–≥–æ–≤–æ–º—É score
        final_results = sorted(combined_results.values(), key=lambda x: x['final_score'], reverse=True)

        return final_results[:k]

    def get_resume_details(self, index):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª–µ–π —Ä–µ–∑—é–º–µ –ø–æ –∏–Ω–¥–µ–∫—Å—É"""
        if index >= len(self.df):
            return None

        row = self.df.iloc[index]

        details = {
            'id': row.get('id', ''),
            'position': row.get('positionName', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'),
            'location': row.get('localityName', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'),
            'age': row.get('age', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'),
            'experience': row.get('experience', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'),
            'education': self.extract_education(row.get('educationList', '')),
            'skills': self.extract_skills(row.get('hardSkills', '')),
            'schedule': row.get('scheduleType', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'),
            'salary': row.get('salary', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'),
            'relocation': row.get('relocation', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')
        }

        return details

    def extract_education(self, education_data):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏"""
        if not education_data or education_data == '[]':
            return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"

        try:
            if isinstance(education_data, str) and 'instituteName' in education_data:
                # –£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∏–Ω—Å—Ç–∏—Ç—É—Ç–∞
                match = re.search(r"'instituteName': '([^']*)'", str(education_data))
                if match:
                    return match.group(1)
            return str(education_data)[:100] + "..." if len(str(education_data)) > 100 else str(education_data)
        except:
            return "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏"

    def extract_skills(self, skills_data):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –Ω–∞–≤—ã–∫–∞—Ö"""
        if not skills_data or skills_data == '[]':
            return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"

        try:
            if isinstance(skills_data, str) and 'hardSkillName' in skills_data:
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π –Ω–∞–≤—ã–∫–æ–≤
                skills = re.findall(r"'hardSkillName': '([^']*)'", str(skills_data))
                if skills:
                    return ", ".join(skills[:5])  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–≤—ã–∫–æ–≤
            return str(skills_data)[:100] + "..." if len(str(skills_data)) > 100 else str(skills_data)
        except:
            return "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏"


# –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
TELEGRAM_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')

if not TELEGRAM_TOKEN:
    raise ValueError("TELEGRAM_BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã
print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã...")
search_engine = ResumeSearchEngine('–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–µ—Å—Å–∏–π.xlsx')
search_engine.preprocess_data()
search_engine.create_faiss_index()


async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
    welcome_text = """
ü§ñ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –±–æ—Ç –ø–æ–∏—Å–∫–∞ —Ä–µ–∑—é–º–µ!

–î–ª—è –ø–æ–∏—Å–∫–∞ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ: –≤–æ–¥–∏—Ç–µ–ª—å; –ú–æ—Å–∫–≤–∞; 5
    """
    await update.message.reply_text(welcome_text)


async def handle_search(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
    try:
        user_input = update.message.text
        parts = user_input.split(';')

        if len(parts) < 3:
            await update.message.reply_text("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: [–¥–æ–ª–∂–Ω–æ—Å—Ç—å]; [–≥–æ—Ä–æ–¥]; [–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ]")
            return

        keyword = parts[0].strip()
        location = parts[1].strip()

        try:
            k = int(parts[2].strip())
            k = min(k, 10)  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –º–∞–∫—Å–∏–º—É–º 10 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        except:
            k = 5

        if not keyword or not location:
            await update.message.reply_text("‚ùå –£–∫–∞–∂–∏—Ç–µ –¥–æ–ª–∂–Ω–æ—Å—Ç—å –∏ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ")
            return

        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–∞
        await update.message.reply_text("üîç –ò—â—É –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Ä–µ–∑—é–º–µ...")

        results = search_engine.hybrid_search(keyword, location, k=k)

        if not results:
            await update.message.reply_text("‚ùå –ü–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ä–µ–∑—é–º–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            return

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
        response = f"üìä –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—é–º–µ: {len(results)}\n\n"

        for i, result in enumerate(results, 1):
            details = search_engine.get_resume_details(result['index'])

            if details:
                response += f"üèÜ **–†–µ–∑—é–º–µ #{i}** (score: {result['final_score']:.2f})\n"
                response += f"üíº –î–æ–ª–∂–Ω–æ—Å—Ç—å: {details['position']}\n"
                response += f"üìç –ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ: {details['location']}\n"
                response += f"üë§ –í–æ–∑—Ä–∞—Å—Ç: {details['age']}\n"
                response += f"üìÖ –û–ø—ã—Ç: {details['experience']} –ª–µ—Ç\n"
                response += f"üéì –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ: {details['education']}\n"
                response += f"üí∞ –ó–∞—Ä–ø–ª–∞—Ç–∞: {details['salary']}\n"
                response += f"üïí –ì—Ä–∞—Ñ–∏–∫: {details['schedule']}\n"
                response += f"üöó –ü–µ—Ä–µ–µ–∑–¥: {details['relocation']}\n"

                if i < len(results):
                    response += "‚îÄ" * 30 + "\n\n"

        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ
        if len(response) > 4096:
            parts = [response[i:i + 4096] for i in range(0, len(response), 4096)]
            for part in parts:
                await update.message.reply_text(part)
        else:
            await update.message.reply_text(response)

    except Exception as e:
        await update.message.reply_text(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}")


async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫"""
    print(f"–û—à–∏–±–∫–∞: {context.error}")
    await update.message.reply_text("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞"""
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    application = Application.builder().token(TELEGRAM_TOKEN).build()

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_search))
    application.add_error_handler(error_handler)

    # –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")
    application.run_polling()


# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã –ø–æ–∏—Å–∫–∞
if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –ø–æ–∏—Å–∫–∞
    print("–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã:")

    # –ü—Ä–∏–º–µ—Ä 1: –ü–æ–∏—Å–∫ –≤–æ–¥–∏—Ç–µ–ª–µ–π –≤ –ú–æ—Å–∫–≤–µ
    results = search_engine.hybrid_search("–≤–æ–¥–∏—Ç–µ–ª—å", "–ú–æ—Å–∫–≤–∞", k=3)
    print(f"\n–ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—é–º–µ –≤–æ–¥–∏—Ç–µ–ª–µ–π –≤ –ú–æ—Å–∫–≤–µ:")
    for i, result in enumerate(results, 1):
        details = search_engine.get_resume_details(result['index'])
        print(f"{i}. {details['position']} - {details['location']} (score: {result['final_score']:.2f})")

    # –ü—Ä–∏–º–µ—Ä 2: –ü–æ–∏—Å–∫ –ø—Ä–æ–¥–∞–≤—Ü–æ–≤ –≤ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥–µ
    results = search_engine.hybrid_search("–ø—Ä–æ–¥–∞–≤–µ—Ü", "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", k=2)
    print(f"\n–ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—é–º–µ –ø—Ä–æ–¥–∞–≤—Ü–æ–≤ –≤ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥–µ:")
    for i, result in enumerate(results, 1):
        details = search_engine.get_resume_details(result['index'])
        print(f"{i}. {details['position']} - {details['location']} (score: {result['final_score']:.2f})")

    # –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ (—Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
    main()